{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleaned 10 chunks from data/scraped_data/brand.vanderbilt.edu/brand.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 10 chunks from data/scraped_data/giving.vanderbilt.edu/giving.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 13 chunks from data/scraped_data/gradschool.vanderbilt.edu/gradschool.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 13 chunks from data/scraped_data/hr.vanderbilt.edu/hr.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 15 chunks from data/scraped_data/medschool.vanderbilt.edu/medschool.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 10 chunks from data/scraped_data/peabody.vanderbilt.edu/peabody.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 17 chunks from data/scraped_data/business.vanderbilt.edu/business.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 33 chunks from data/scraped_data/news.vanderbilt.edu/news.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 2 chunks from data/scraped_data/studentorg.vanderbilt.edu/studentorg.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 20 chunks from data/scraped_data/law.vanderbilt.edu/law.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 1 chunks from data/scraped_data/it.vanderbilt.edu/it.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 2 chunks from data/scraped_data/emergency.vanderbilt.edu/emergency.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 18 chunks from data/scraped_data/engineering.vanderbilt.edu/engineering.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 5 chunks from data/scraped_data/research.vanderbilt.edu/research.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 17 chunks from data/scraped_data/divinity.vanderbilt.edu/divinity.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 9 chunks from data/scraped_data/vanderbilt.edu/vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 10 chunks from data/scraped_data/as.vanderbilt.edu/as.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 2 chunks from data/scraped_data/campusdining.vanderbilt.edu/campusdining.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 2 chunks from data/scraped_data/info.engineering.vanderbilt.edu/info.engineering.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 15 chunks from data/scraped_data/admissions.vanderbilt.edu/admissions.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 2 chunks from data/scraped_data/wp0.vanderbilt.edu/wp0.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 1 chunks from data/scraped_data/events.vanderbilt.edu/events.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 48 chunks from data/scraped_data/www.vanderbilt.edu/www.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 8 chunks from data/scraped_data/blair.vanderbilt.edu/blair.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 11 chunks from data/scraped_data/my.vanderbilt.edu/my.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 2 chunks from data/scraped_data/www4.vanderbilt.edu/www4.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 7 chunks from data/scraped_data/nursing.vanderbilt.edu/nursing.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 11 chunks from data/scraped_data/registrar.vanderbilt.edu/registrar.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 1 chunks from data/scraped_data/publicsafety.vanderbilt.edu/publicsafety.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 1 chunks from data/scraped_data/commonplace.vanderbilt.edu/commonplace.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 7 chunks from data/scraped_data/finance.vanderbilt.edu/finance.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 2 chunks from data/scraped_data/police.vanderbilt.edu/police.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 3 chunks from data/scraped_data/studenthandbook.vanderbilt.edu/studenthandbook.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 1 chunks from data/scraped_data/printingservices.vanderbilt.edu/printingservices.vanderbilt.edu_part1.txt.json\n",
      "üßπ Cleaned 7 chunks from data/scraped_data/eecs.vanderbilt.edu/eecs.vanderbilt.edu_part1.txt.json\n",
      "‚úÖ Finished cleaning all JSON files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Define the root directory containing JSON files\n",
    "ROOT_DIR = \"data/scraped_data\"\n",
    "\n",
    "def clean_json_file(json_path):\n",
    "    \"\"\"Removes chunks that contain only '=' characters from the JSON file.\"\"\"\n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            chunks = json.load(f)\n",
    "\n",
    "        # Filter out chunks where the \"text\" field contains only '=' (any number of them)\n",
    "        cleaned_chunks = [chunk for chunk in chunks if not re.fullmatch(r\"=+\", chunk.get(\"text\", \"\").strip())]\n",
    "\n",
    "        if len(cleaned_chunks) != len(chunks):\n",
    "            print(f\"üßπ Cleaned {len(chunks) - len(cleaned_chunks)} chunks from {json_path}\")\n",
    "\n",
    "            # Save the cleaned data back to the same JSON file\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(cleaned_chunks, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"‚ö†Ô∏è Skipping {json_path}: Invalid JSON format.\")\n",
    "\n",
    "def clean_all_json_files(root_dir):\n",
    "    \"\"\"Loops through all subfolders in the root directory and cleans each JSON file.\"\"\"\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                json_path = os.path.join(subdir, file)\n",
    "                clean_json_file(json_path)\n",
    "\n",
    "# Run the cleaning process\n",
    "if __name__ == \"__main__\":\n",
    "    clean_all_json_files(ROOT_DIR)\n",
    "    print(\"‚úÖ Finished cleaning all JSON files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Connecting to ChromaDB...\n",
      "üì¶ Adding dummy chunk: ===\n",
      "‚úÖ Dummy chunk added successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import uuid\n",
    "\n",
    "# Define the directory where ChromaDB is stored\n",
    "CHROMA_DB_DIR = \"../chroma_db\"\n",
    "COLLECTION_NAME = \"WebsiteData\"  # Adjust based on your setup\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the vector store\n",
    "print(\"üîç Connecting to ChromaDB...\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = Chroma(collection_name=COLLECTION_NAME, embedding_function=embeddings, persist_directory=CHROMA_DB_DIR)\n",
    "\n",
    "# Create a dummy document\n",
    "dummy_text = \"===\"  # Content with only '=' characters\n",
    "dummy_doc = Document(\n",
    "    page_content=dummy_text,\n",
    "    metadata={\"id\": str(uuid.uuid4()), \"source\": \"dummy_test\", \"chunk_number\": 999}\n",
    ")\n",
    "\n",
    "# Add to vector store\n",
    "print(f\"üì¶ Adding dummy chunk: {dummy_doc.page_content}\")\n",
    "vector_store.add_documents([dummy_doc])\n",
    "\n",
    "print(\"‚úÖ Dummy chunk added successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Connecting to ChromaDB...\n",
      "üì• Retrieving documents from 'WebsiteData' collection...\n",
      "üìå Found 6760 documents in vector store.\n",
      "üóëÔ∏è Removing 674 invalid documents...\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m valid_to_remove \u001b[38;5;241m=\u001b[39m [id_ \u001b[38;5;28;01mfor\u001b[39;00m id_ \u001b[38;5;129;01min\u001b[39;00m to_remove_ids \u001b[38;5;28;01mif\u001b[39;00m id_ \u001b[38;5;129;01min\u001b[39;00m stored_ids]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid_to_remove:\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_to_remove\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Successfully removed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(valid_to_remove)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m documents.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/RandyCode/venv/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:1257\u001b[0m, in \u001b[0;36mChroma.delete\u001b[0;34m(self, ids, **kwargs)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdelete\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Delete by vector IDs.\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m \n\u001b[1;32m   1253\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;124;03m        ids: List of ids to delete.\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;124;03m        kwargs: Additional keyword arguments.\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RandyCode/venv/lib/python3.12/site-packages/chromadb/api/models/Collection.py:378\u001b[0m, in \u001b[0;36mCollection.delete\u001b[0;34m(self, ids, where, where_document)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Delete the embeddings based on ids and/or a where filter\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    ValueError: If you don't provide either ids, where, or where_document\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m delete_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_delete_request(\n\u001b[1;32m    375\u001b[0m     ids, where, where_document\n\u001b[1;32m    376\u001b[0m )\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelete_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelete_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhere_document\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelete_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhere_document\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RandyCode/venv/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/RandyCode/venv/lib/python3.12/site-packages/chromadb/api/segment.py:103\u001b[0m, in \u001b[0;36mrate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rate_limit_enforcer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate_limit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RandyCode/venv/lib/python3.12/site-packages/chromadb/rate_limit/simple_rate_limit/__init__.py:24\u001b[0m, in \u001b[0;36mSimpleRateLimitEnforcer.rate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/RandyCode/venv/lib/python3.12/site-packages/chromadb/api/segment.py:721\u001b[0m, in \u001b[0;36mSegmentAPI._delete\u001b[0;34m(self, collection_id, ids, where, where_document, tenant, database)\u001b[0m\n\u001b[1;32m    717\u001b[0m records_to_submit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    718\u001b[0m     _records(operation\u001b[38;5;241m=\u001b[39mt\u001b[38;5;241m.\u001b[39mOperation\u001b[38;5;241m.\u001b[39mDELETE, ids\u001b[38;5;241m=\u001b[39mids_to_delete)\n\u001b[1;32m    719\u001b[0m )\n\u001b[1;32m    720\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_embedding_record_set(scan\u001b[38;5;241m.\u001b[39mcollection, records_to_submit)\n\u001b[0;32m--> 721\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_producer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords_to_submit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_product_telemetry_client\u001b[38;5;241m.\u001b[39mcapture(\n\u001b[1;32m    724\u001b[0m     CollectionDeleteEvent(\n\u001b[1;32m    725\u001b[0m         collection_uuid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(collection_id), delete_amount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(ids_to_delete)\n\u001b[1;32m    726\u001b[0m     )\n\u001b[1;32m    727\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/RandyCode/venv/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/RandyCode/venv/lib/python3.12/site-packages/chromadb/db/mixins/embeddings_queue.py:243\u001b[0m, in \u001b[0;36mSqlEmbeddingsQueue.submit_embeddings\u001b[0;34m(self, collection_id, embeddings)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# The returning clause does not guarantee order, so we need to do reorder\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# the results. https://www.sqlite.org/lang_returning.html\u001b[39;00m\n\u001b[1;32m    242\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RETURNING seq_id, id\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Pypika doesn't support RETURNING\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Reorder the results\u001b[39;00m\n\u001b[1;32m    245\u001b[0m seq_ids \u001b[38;5;241m=\u001b[39m [cast(SeqId, \u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    246\u001b[0m     results\n\u001b[1;32m    247\u001b[0m )  \u001b[38;5;66;03m# Lie to mypy: https://stackoverflow.com/questions/76694215/python-type-casting-when-preallocating-list\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: attempt to write a readonly database"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Define the directory where ChromaDB is stored\n",
    "CHROMA_DB_DIR = \"../chroma_db\"  # Adjust based on your actual path\n",
    "COLLECTION_NAME = \"WebsiteData\"  # Ensure this matches your collection name\n",
    "\n",
    "# Initialize the vector store\n",
    "print(\"üîç Connecting to ChromaDB...\")\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vector_store = Chroma(collection_name=COLLECTION_NAME, embedding_function=embeddings, persist_directory=CHROMA_DB_DIR)\n",
    "\n",
    "# Retrieve all documents and their metadata (without IDs)\n",
    "print(f\"üì• Retrieving documents from '{COLLECTION_NAME}' collection...\")\n",
    "all_docs = vector_store.get(include=[\"documents\", \"metadatas\"])  # No \"ids\" option\n",
    "\n",
    "documents = all_docs.get(\"documents\", [])\n",
    "metadatas = all_docs.get(\"metadatas\", [])\n",
    "\n",
    "print(f\"üìå Found {len(documents)} documents in vector store.\")\n",
    "\n",
    "# Extract stored IDs from metadata\n",
    "stored_ids = [meta.get(\"id\") for meta in metadatas if \"id\" in meta]  # Retrieve IDs if stored\n",
    "\n",
    "# Filter documents that contain only '=' characters\n",
    "to_remove_ids = [\n",
    "    stored_ids[i] for i, doc in enumerate(documents) if re.fullmatch(r\"=+\", doc.strip()) and stored_ids[i]\n",
    "]\n",
    "\n",
    "if not to_remove_ids:\n",
    "    print(\"‚úÖ No invalid documents found. Nothing to remove.\")\n",
    "else:\n",
    "    print(f\"üóëÔ∏è Removing {len(to_remove_ids)} invalid documents...\")\n",
    "\n",
    "    # Remove only if valid IDs exist\n",
    "    valid_to_remove = [id_ for id_ in to_remove_ids if id_ in stored_ids]\n",
    "\n",
    "    if valid_to_remove:\n",
    "        vector_store.delete(ids=valid_to_remove)\n",
    "        print(f\"‚úÖ Successfully removed {len(valid_to_remove)} documents.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No matching document IDs found in the database. Nothing to remove.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
